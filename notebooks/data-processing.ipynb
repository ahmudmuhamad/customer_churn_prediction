{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import jsonschema_specifications\n",
    "import json\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.read_json(r\"E:\\customer_churn_prediction\\data\\interim\\events.json\", lines = True)\n",
    "full_events = pd.read_json(r\"E:\\customer_churn_prediction\\data\\interim\\cleaned_test_data.json\", lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events: (278154, 18)\n",
      "full_events: (248377, 18)\n"
     ]
    }
   ],
   "source": [
    "print(\"events:\", events.shape)\n",
    "print(\"full_events:\", full_events.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ts', 'userId', 'sessionId', 'page', 'auth', 'method', 'status',\n",
       "       'level', 'itemInSession', 'location', 'userAgent', 'lastName',\n",
       "       'firstName', 'registration', 'gender', 'artist', 'song', 'length'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ts', 'userId', 'sessionId', 'page', 'auth', 'method', 'status',\n",
       "       'level', 'itemInSession', 'location', 'userAgent', 'lastName',\n",
       "       'firstName', 'registration', 'gender', 'artist', 'song', 'length'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_events.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Churn Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique users (events): 225\n"
     ]
    }
   ],
   "source": [
    "if 'churn' not in events.columns:\n",
    "    events_sorted = events.sort_values(['userId', 'ts'])\n",
    "    user_last_events = events_sorted.groupby('userId').tail(1).copy()\n",
    "    user_last_events['churn'] = (user_last_events['page'] == 'Cancellation Confirmation').astype(int)\n",
    "    user_churn_map = user_last_events[['userId', 'churn']].set_index('userId')['churn'].to_dict()\n",
    "    events['churn'] = events['userId'].map(user_churn_map).fillna(0).astype(int)\n",
    "else:\n",
    "    # ensure mapping is consistent\n",
    "    events_sorted = events.sort_values(['userId', 'ts'])\n",
    "    user_last_events = events_sorted.groupby('userId').tail(1).copy()\n",
    "\n",
    "print(\"unique users (events):\", events['userId'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ts', 'userId', 'sessionId', 'page', 'auth', 'method', 'status',\n",
       "       'level', 'itemInSession', 'location', 'userAgent', 'lastName',\n",
       "       'firstName', 'registration', 'gender', 'artist', 'song', 'length',\n",
       "       'churn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ts', 'userId', 'sessionId', 'page', 'auth', 'method', 'status',\n",
       "       'level', 'itemInSession', 'location', 'userAgent', 'lastName',\n",
       "       'firstName', 'registration', 'gender', 'artist', 'song', 'length'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_events.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reassuring that there is no overlap between the training and testing data (Made before but I will check again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap count: 0\n",
      "No overlap found.\n"
     ]
    }
   ],
   "source": [
    "train_user_ids = set(events['userId'].unique())\n",
    "test_user_ids = set(full_events['userId'].unique())\n",
    "\n",
    "overlap = train_user_ids.intersection(test_user_ids)\n",
    "print(\"overlap count:\", len(overlap))\n",
    "\n",
    "\n",
    "if len(overlap) > 0:\n",
    "    full_events_clean = full_events[~full_events['userId'].isin(overlap)].copy()\n",
    "    print(f\"Removed {len(overlap)} overlapping users from full_events -> full_events_clean shape: {full_events_clean.shape}\")\n",
    "else:\n",
    "    full_events_clean = full_events.copy()\n",
    "    print(\"No overlap found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "churn\n",
       "0    233290\n",
       "1     44864\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.churn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train user churn value counts:\n",
      " churn\n",
      "0    173\n",
      "1     52\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if 'churn' not in events.columns or events['churn'].isnull().any():\n",
    "    ev_sorted = events.sort_values(['userId','ts'])\n",
    "    last = ev_sorted.groupby('userId').tail(1).copy()\n",
    "    user_churn = last.set_index('userId')['page'].eq('Cancellation Confirmation').astype(int)\n",
    "else:\n",
    "    user_churn = events.groupby('userId').tail(1).set_index('userId')['churn']\n",
    "\n",
    "print(\"train user churn value counts:\\n\", user_churn.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test user churn value counts:\n",
      " page\n",
      "0    176\n",
      "1     48\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# test user churn\n",
    "fe_sorted = full_events_clean.sort_values(['userId','ts'])\n",
    "fe_last = fe_sorted.groupby('userId').tail(1).copy()\n",
    "test_user_churn = fe_last.set_index('userId')['page'].eq('Cancellation Confirmation').astype(int)\n",
    "print(\"test user churn value counts:\\n\", test_user_churn.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events per user (train) — mean, median, min, max: 1236.24 848.0 6 9632\n",
      "how many users with only 1 event: 0\n",
      "events-per-user quantiles:\n",
      " 0.00       6.00\n",
      "0.25     296.00\n",
      "0.50     848.00\n",
      "0.75    1863.00\n",
      "0.90    2514.00\n",
      "0.99    6604.48\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 3) events per user distribution (basic stats + tails)\n",
    "ev_per_user = events.groupby('userId').size()\n",
    "print(\"events per user (train) — mean, median, min, max:\", ev_per_user.mean(), ev_per_user.median(), ev_per_user.min(), ev_per_user.max())\n",
    "print(\"how many users with only 1 event:\", (ev_per_user==1).sum())\n",
    "print(\"events-per-user quantiles:\\n\", ev_per_user.quantile([0.0,0.25,0.5,0.75,0.9,0.99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total train users: 225 total churn positives: 52 positive rate: 0.2311111111111111\n",
      "approx pos per fold if n_splits=3: 17.33\n",
      "approx pos per fold if n_splits=4: 13.00\n",
      "approx pos per fold if n_splits=5: 10.40\n",
      "approx pos per fold if n_splits=10: 5.20\n"
     ]
    }
   ],
   "source": [
    "# 4) churn positives per prospective CV fold (approx)\n",
    "n_users = len(train_user_ids)\n",
    "churn_pos = user_churn.sum()\n",
    "print(\"total train users:\", n_users, \"total churn positives:\", churn_pos, \"positive rate:\", churn_pos/n_users)\n",
    "for n_splits in (3,4,5,10):\n",
    "    approx_pos_per_fold = churn_pos / n_splits\n",
    "    print(f\"approx pos per fold if n_splits={n_splits}: {approx_pos_per_fold:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users with cancellation then later events: 0\n"
     ]
    }
   ],
   "source": [
    "# 5) sanity: users that have cancellation event but more events after it\n",
    "canc_users = events[events['page']=='Cancellation Confirmation']['userId'].unique()\n",
    "after_cancel = []\n",
    "for u in canc_users:\n",
    "    uev = events[events['userId']==u].sort_values('ts')\n",
    "    canc_idx = uev[uev['page']=='Cancellation Confirmation'].index.min()\n",
    "    if canc_idx < uev.index.max():  # there are events after the first cancellation\n",
    "        after_cancel.append(u)\n",
    "print(\"users with cancellation then later events:\", len(after_cancel))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building user-level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_user_features(events_df):\n",
    "    # events_df: event-level data (must include 'userId', 'ts', 'song','artist','length','sessionId','itemInSession','page','level')\n",
    "    df_sorted = events_df.sort_values(['userId', 'ts']).copy()\n",
    "    # get each user's last-event index\n",
    "    last_idx = df_sorted.groupby('userId').tail(1).index\n",
    "    # events without the last event for each user (these will be used to compute features)\n",
    "    df_no_last = df_sorted.drop(index=last_idx)\n",
    "    # For users who only had 1 event, dropping leaves 0 rows -> we'll fill missing features later\n",
    "    agg = df_no_last.groupby('userId').agg(\n",
    "        total_events=('ts', 'count'),\n",
    "        n_sessions=('sessionId', pd.Series.nunique),\n",
    "        unique_songs=('song', pd.Series.nunique),\n",
    "        unique_artists=('artist', pd.Series.nunique),\n",
    "        total_length=('length', 'sum'),\n",
    "        avg_length=('length', 'mean'),\n",
    "        avg_itemInSession=('itemInSession', 'mean'),\n",
    "        num_cancellation_events=('page', lambda s: (s == 'Cancellation Confirmation').sum()),\n",
    "        num_thumbup=('page', lambda s: (s == 'Thumbs Up').sum()),\n",
    "        num_thumbdown=('page', lambda s: (s == 'Thumbs Down').sum()),\n",
    "        num_home=('page', lambda s: (s == 'Home').sum()),\n",
    "        num_nextsong=('page', lambda s: (s == 'NextSong').sum()),\n",
    "        last_level=('level', lambda s: s.iloc[-1] if len(s)>0 else np.nan),\n",
    "        last_location=('location', lambda s: s.iloc[-1] if len(s)>0 else np.nan),\n",
    "        first_ts=('ts', 'min'),\n",
    "        last_ts_excluded=('ts', 'max')\n",
    "    ).reset_index()\n",
    "\n",
    "    # compute activity span in seconds (last - first)\n",
    "    agg['activity_span_seconds'] = (agg['last_ts_excluded'] - agg['first_ts']).fillna(0)\n",
    "    # fill NA numeric features with 0\n",
    "    numeric_cols = ['total_events','n_sessions','unique_songs','unique_artists','total_length','avg_length',\n",
    "                    'avg_itemInSession','num_cancellation_events','num_thumbup','num_thumbdown','num_home','num_nextsong','activity_span_seconds']\n",
    "    agg[numeric_cols] = agg[numeric_cols].fillna(0)\n",
    "    # last_level / last_location: fill missing with 'unknown'\n",
    "    agg['last_level'] = agg['last_level'].fillna('unknown')\n",
    "    agg['last_location'] = agg['last_location'].fillna('unknown')\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build training user features\n",
    "train_user_feats = build_user_features(events)\n",
    "# get labels from true last event per user\n",
    "train_labels = user_last_events[['userId','churn']].drop_duplicates(subset=['userId']).set_index('userId')\n",
    "train_user_feats = train_user_feats.set_index('userId').join(train_labels, how='left')\n",
    "train_user_feats['churn'] = train_user_feats['churn'].fillna(0).astype(int)\n",
    "train_user_feats = train_user_feats.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_user_feats: (225, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>total_events</th>\n",
       "      <th>n_sessions</th>\n",
       "      <th>unique_songs</th>\n",
       "      <th>unique_artists</th>\n",
       "      <th>total_length</th>\n",
       "      <th>avg_length</th>\n",
       "      <th>avg_itemInSession</th>\n",
       "      <th>num_cancellation_events</th>\n",
       "      <th>num_thumbup</th>\n",
       "      <th>num_thumbdown</th>\n",
       "      <th>num_home</th>\n",
       "      <th>num_nextsong</th>\n",
       "      <th>last_level</th>\n",
       "      <th>last_location</th>\n",
       "      <th>first_ts</th>\n",
       "      <th>last_ts_excluded</th>\n",
       "      <th>activity_span_seconds</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>898</td>\n",
       "      <td>7</td>\n",
       "      <td>713</td>\n",
       "      <td>587</td>\n",
       "      <td>188687.38342</td>\n",
       "      <td>249.917064</td>\n",
       "      <td>137.935412</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>755</td>\n",
       "      <td>paid</td>\n",
       "      <td>Raleigh, NC</td>\n",
       "      <td>1538974195000</td>\n",
       "      <td>1542839403000</td>\n",
       "      <td>3865208000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>253</td>\n",
       "      <td>4</td>\n",
       "      <td>211</td>\n",
       "      <td>197</td>\n",
       "      <td>54424.74544</td>\n",
       "      <td>254.321240</td>\n",
       "      <td>46.592885</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>214</td>\n",
       "      <td>paid</td>\n",
       "      <td>Bozeman, MT</td>\n",
       "      <td>1538532534000</td>\n",
       "      <td>1540874979000</td>\n",
       "      <td>2342445000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2441</td>\n",
       "      <td>22</td>\n",
       "      <td>1799</td>\n",
       "      <td>1342</td>\n",
       "      <td>506140.04138</td>\n",
       "      <td>247.138692</td>\n",
       "      <td>152.165916</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>26</td>\n",
       "      <td>80</td>\n",
       "      <td>2048</td>\n",
       "      <td>paid</td>\n",
       "      <td>Baltimore-Columbia-Towson, MD</td>\n",
       "      <td>1538356650000</td>\n",
       "      <td>1543595542000</td>\n",
       "      <td>5238892000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>217</td>\n",
       "      <td>6</td>\n",
       "      <td>159</td>\n",
       "      <td>154</td>\n",
       "      <td>39525.04698</td>\n",
       "      <td>245.497186</td>\n",
       "      <td>28.193548</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>161</td>\n",
       "      <td>free</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>1538581469000</td>\n",
       "      <td>1541637200000</td>\n",
       "      <td>3055731000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>3760</td>\n",
       "      <td>24</td>\n",
       "      <td>2678</td>\n",
       "      <td>1868</td>\n",
       "      <td>787236.52359</td>\n",
       "      <td>249.204344</td>\n",
       "      <td>172.839362</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>31</td>\n",
       "      <td>131</td>\n",
       "      <td>3159</td>\n",
       "      <td>paid</td>\n",
       "      <td>Houston-The Woodlands-Sugar Land, TX</td>\n",
       "      <td>1538406703000</td>\n",
       "      <td>1543531621000</td>\n",
       "      <td>5124918000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  total_events  n_sessions  unique_songs  unique_artists  \\\n",
       "0       2           898           7           713             587   \n",
       "1       3           253           4           211             197   \n",
       "2       4          2441          22          1799            1342   \n",
       "3       5           217           6           159             154   \n",
       "4       6          3760          24          2678            1868   \n",
       "\n",
       "   total_length  avg_length  avg_itemInSession  num_cancellation_events  \\\n",
       "0  188687.38342  249.917064         137.935412                        0   \n",
       "1   54424.74544  254.321240          46.592885                        0   \n",
       "2  506140.04138  247.138692         152.165916                        0   \n",
       "3   39525.04698  245.497186          28.193548                        0   \n",
       "4  787236.52359  249.204344         172.839362                        0   \n",
       "\n",
       "   num_thumbup  num_thumbdown  num_home  num_nextsong last_level  \\\n",
       "0           29              6        35           755       paid   \n",
       "1           14              3         8           214       paid   \n",
       "2           95             26        80          2048       paid   \n",
       "3           11              0        14           161       free   \n",
       "4          165             31       131          3159       paid   \n",
       "\n",
       "                          last_location       first_ts  last_ts_excluded  \\\n",
       "0                           Raleigh, NC  1538974195000     1542839403000   \n",
       "1                           Bozeman, MT  1538532534000     1540874979000   \n",
       "2         Baltimore-Columbia-Towson, MD  1538356650000     1543595542000   \n",
       "3           Phoenix-Mesa-Scottsdale, AZ  1538581469000     1541637200000   \n",
       "4  Houston-The Woodlands-Sugar Land, TX  1538406703000     1543531621000   \n",
       "\n",
       "   activity_span_seconds  churn  \n",
       "0             3865208000      0  \n",
       "1             2342445000      1  \n",
       "2             5238892000      0  \n",
       "3             3055731000      0  \n",
       "4             5124918000      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"train_user_feats:\", train_user_feats.shape)\n",
    "train_user_feats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build test user features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sorted = full_events_clean.sort_values(['userId', 'ts']).copy()\n",
    "test_user_last = full_sorted.groupby('userId').tail(1).copy()\n",
    "test_user_last['churn'] = (test_user_last['page'] == 'Cancellation Confirmation').astype(int)\n",
    "\n",
    "test_user_feats = build_user_features(full_events_clean)\n",
    "test_labels = test_user_last[['userId','churn']].drop_duplicates(subset=['userId']).set_index('userId')\n",
    "test_user_feats = test_user_feats.set_index('userId').join(test_labels, how='left')\n",
    "test_user_feats['churn'] = test_user_feats['churn'].fillna(0).astype(int)\n",
    "test_user_feats = test_user_feats.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_user_feats: (224, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>total_events</th>\n",
       "      <th>n_sessions</th>\n",
       "      <th>unique_songs</th>\n",
       "      <th>unique_artists</th>\n",
       "      <th>total_length</th>\n",
       "      <th>avg_length</th>\n",
       "      <th>avg_itemInSession</th>\n",
       "      <th>num_cancellation_events</th>\n",
       "      <th>num_thumbup</th>\n",
       "      <th>num_thumbdown</th>\n",
       "      <th>num_home</th>\n",
       "      <th>num_nextsong</th>\n",
       "      <th>last_level</th>\n",
       "      <th>last_location</th>\n",
       "      <th>first_ts</th>\n",
       "      <th>last_ts_excluded</th>\n",
       "      <th>activity_span_seconds</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>380</td>\n",
       "      <td>4</td>\n",
       "      <td>287</td>\n",
       "      <td>264</td>\n",
       "      <td>78848.35933</td>\n",
       "      <td>261.087283</td>\n",
       "      <td>69.744737</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>302</td>\n",
       "      <td>paid</td>\n",
       "      <td>Jackson, MS</td>\n",
       "      <td>1538681898000</td>\n",
       "      <td>1541092581000</td>\n",
       "      <td>2410683000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130</td>\n",
       "      <td>363</td>\n",
       "      <td>7</td>\n",
       "      <td>264</td>\n",
       "      <td>249</td>\n",
       "      <td>71482.73064</td>\n",
       "      <td>262.804157</td>\n",
       "      <td>37.752066</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>272</td>\n",
       "      <td>free</td>\n",
       "      <td>Bridgeport-Stamford-Norwalk, CT</td>\n",
       "      <td>1538482298000</td>\n",
       "      <td>1538890857000</td>\n",
       "      <td>408559000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>157</td>\n",
       "      <td>2965</td>\n",
       "      <td>20</td>\n",
       "      <td>2174</td>\n",
       "      <td>1585</td>\n",
       "      <td>617699.17649</td>\n",
       "      <td>247.079671</td>\n",
       "      <td>188.997976</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>27</td>\n",
       "      <td>86</td>\n",
       "      <td>2500</td>\n",
       "      <td>paid</td>\n",
       "      <td>Tullahoma-Manchester, TN</td>\n",
       "      <td>1538744376000</td>\n",
       "      <td>1543292957000</td>\n",
       "      <td>4548581000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>158</td>\n",
       "      <td>130</td>\n",
       "      <td>4</td>\n",
       "      <td>89</td>\n",
       "      <td>87</td>\n",
       "      <td>23648.74337</td>\n",
       "      <td>265.716218</td>\n",
       "      <td>39.984615</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>89</td>\n",
       "      <td>free</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
       "      <td>1539238077000</td>\n",
       "      <td>1542605535000</td>\n",
       "      <td>3367458000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>159</td>\n",
       "      <td>417</td>\n",
       "      <td>12</td>\n",
       "      <td>306</td>\n",
       "      <td>287</td>\n",
       "      <td>80522.48812</td>\n",
       "      <td>254.014158</td>\n",
       "      <td>34.462830</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>317</td>\n",
       "      <td>free</td>\n",
       "      <td>New Orleans-Metairie, LA</td>\n",
       "      <td>1538543900000</td>\n",
       "      <td>1543577819000</td>\n",
       "      <td>5033919000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  total_events  n_sessions  unique_songs  unique_artists  \\\n",
       "0      48           380           4           287             264   \n",
       "1     130           363           7           264             249   \n",
       "2     157          2965          20          2174            1585   \n",
       "3     158           130           4            89              87   \n",
       "4     159           417          12           306             287   \n",
       "\n",
       "   total_length  avg_length  avg_itemInSession  num_cancellation_events  \\\n",
       "0   78848.35933  261.087283          69.744737                        0   \n",
       "1   71482.73064  262.804157          37.752066                        0   \n",
       "2  617699.17649  247.079671         188.997976                        0   \n",
       "3   23648.74337  265.716218          39.984615                        0   \n",
       "4   80522.48812  254.014158          34.462830                        0   \n",
       "\n",
       "   num_thumbup  num_thumbdown  num_home  num_nextsong last_level  \\\n",
       "0           19              6        15           302       paid   \n",
       "1           14              2        16           272       free   \n",
       "2          115             27        86          2500       paid   \n",
       "3            5              2        10            89       free   \n",
       "4           15              4        21           317       free   \n",
       "\n",
       "                           last_location       first_ts  last_ts_excluded  \\\n",
       "0                            Jackson, MS  1538681898000     1541092581000   \n",
       "1        Bridgeport-Stamford-Norwalk, CT  1538482298000     1538890857000   \n",
       "2               Tullahoma-Manchester, TN  1538744376000     1543292957000   \n",
       "3  New York-Newark-Jersey City, NY-NJ-PA  1539238077000     1542605535000   \n",
       "4               New Orleans-Metairie, LA  1538543900000     1543577819000   \n",
       "\n",
       "   activity_span_seconds  churn  \n",
       "0             2410683000      0  \n",
       "1              408559000      1  \n",
       "2             4548581000      0  \n",
       "3             3367458000      0  \n",
       "4             5033919000      0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"test_user_feats:\", test_user_feats.shape)\n",
    "test_user_feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train_user_feats: rows=225, cols=19\n",
      "  csv -> E:\\customer_churn_prediction\\data\\processed\\train_user_feats.csv\n",
      "  jsonl -> E:\\customer_churn_prediction\\data\\processed\\train_user_feats.jsonl\n",
      "  parquet -> E:\\customer_churn_prediction\\data\\processed\\train_user_feats.parquet\n",
      "  metadata -> E:\\customer_churn_prediction\\data\\processed\\train_user_feats_metadata.json\n",
      "----\n",
      "Saved test_user_feats: rows=224, cols=19\n",
      "  csv -> E:\\customer_churn_prediction\\data\\processed\\test_user_feats.csv\n",
      "  jsonl -> E:\\customer_churn_prediction\\data\\processed\\test_user_feats.jsonl\n",
      "  parquet -> E:\\customer_churn_prediction\\data\\processed\\test_user_feats.parquet\n",
      "  metadata -> E:\\customer_churn_prediction\\data\\processed\\test_user_feats_metadata.json\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "out_dir = r\"E:\\customer_churn_prediction\\data\\processed\"\n",
    "expected = {\n",
    "    \"train_user_feats\": globals().get(\"train_user_feats\", None),\n",
    "    \"test_user_feats\": globals().get(\"test_user_feats\", None)\n",
    "}\n",
    "\n",
    "for name, df in expected.items():\n",
    "    if df is None:\n",
    "        raise RuntimeError(f\"DataFrame '{name}' not found in the notebook. Make sure you ran the feature-building cells first.\")\n",
    "    # normalize index (save userId as column if it's the index)\n",
    "    if df.index.name == 'userId' or (df.index.name is None and 'userId' not in df.columns and df.index.dtype == object):\n",
    "        df_to_save = df.reset_index()\n",
    "    else:\n",
    "        df_to_save = df.copy()\n",
    "\n",
    "    # file paths\n",
    "    csv_path = os.path.join(out_dir, f\"{name}.csv\")\n",
    "    jsonl_path = os.path.join(out_dir, f\"{name}.jsonl\")\n",
    "    parquet_path = os.path.join(out_dir, f\"{name}.parquet\")\n",
    "    meta_path = os.path.join(out_dir, f\"{name}_metadata.json\")\n",
    "\n",
    "    # save\n",
    "    df_to_save.to_csv(csv_path, index=False)\n",
    "    df_to_save.to_json(jsonl_path, orient=\"records\", lines=True)\n",
    "    try:\n",
    "        df_to_save.to_parquet(parquet_path, index=False)\n",
    "    except Exception as e:\n",
    "        # parquet may require pyarrow or fastparquet; warn but continue\n",
    "        print(f\"Warning: could not write parquet for {name} ({e}). Install pyarrow or fastparquet to enable parquet saving.\")\n",
    "\n",
    "    # metadata\n",
    "    meta = {\n",
    "        \"rows\": int(df_to_save.shape[0]),\n",
    "        \"cols\": int(df_to_save.shape[1]),\n",
    "        \"columns\": list(map(str, df_to_save.columns)),\n",
    "        \"csv\": csv_path,\n",
    "        \"jsonl\": jsonl_path,\n",
    "        \"parquet\": parquet_path if os.path.exists(parquet_path) else None\n",
    "    }\n",
    "    with open(meta_path, \"w\", encoding=\"utf-8\") as fh:\n",
    "        json.dump(meta, fh, indent=2)\n",
    "\n",
    "    print(f\"Saved {name}: rows={meta['rows']}, cols={meta['cols']}\")\n",
    "    print(f\"  csv -> {csv_path}\")\n",
    "    print(f\"  jsonl -> {jsonl_path}\")\n",
    "    if meta[\"parquet\"]:\n",
    "        print(f\"  parquet -> {parquet_path}\")\n",
    "    print(f\"  metadata -> {meta_path}\")\n",
    "    print(\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
